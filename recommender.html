<!DOCTYPE HTML>
<html>
<head>
    <title>Recommender</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <!-- External library import -->
    <link rel="stylesheet" href="assets/css/lib/main.css" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">
</head>
<body>
    <!-- Page Wrapper -->
    <div id="page-wrapper">
        <!-- Header -->
        <header id="header">
            <h1><a href="index.html">Back</a></h1>
            <nav>
                <a href="">Source Code</a>
            </nav>
        </header>
        <!-- Wrapper -->
        <section id="wrapper">
            <!-- Title -->
            <header>
                <div class="inner">
                    <h2>Recommender System</h2>
                    <p>Using collaborative filtering to provide product recommendations</p>
                </div>
            </header>
            <!-- Content -->
            <div class="wrapper">
                <!-- Main Content -->
                <div class="inner">
                    <section>
                        <h2 class="major">Consilium</h3>
                        <p>
                            Consilium is a movie recommender web application. It starts by asking new users to rate movies they have seen. The data
                            will then be used to determine users' taste and preference for movies. There are two distinct algorithms powering the
                            application and they both belong to the class of collaborative filtering.
                        </p>
                        <h3>So what is collaborative filtering?</h4>
                        <p>
                            Imagine you are shopping for a new pair of shoes. There are many seemingly trendy options to pick from. You are
                            having a hard time to decide which style and which color to go for. How do you resolve a dilemma like this? You'd start
                            asking people for second opinion. You'd ask people who share similar taste and preference with you because chance is,
                            if they like something, you will also like it. Collaborative filtering is a process of grouping similar users together
                            and filter for most liked items within the group, i.e. grouping you with your peers and recommend you products that are most liked
                            by your peers.
                        </p>

                        <h2 class="major">k-Nearest Neighbor</h3>
                        <p>
                            The first algorithm we need to talk about is called k-Nearest Neighbor. It's basically consulting the k number of users that are most similar
                            to you in terms of taste and preference for movies. Using those k number of users as input, the algorithm will make a rating prediction on a
                            given movie.
                        </p>
                        <h4>What does "similar" mean?</h4>
                        <p>
                            We can mathematically quantify how similar two users are by looking at their rating patterns on products (in our case, it's movies.)
                        </p>

                        <h3>Mathematical Formulations</h4>
                        <h4>Computing similarity</h4>
                        <blockquote>
                            <p>
                            I<sub>u</sub> is the set of movies that user <strong>u</strong> has rated and I<sub>v</sub> is the set of movies that user <strong>v</strong>
                                has rated. The notation is saying that, iterate through teh set of movies that both users have rated.
                            </p>
                            <p id="sim-coeff"></p>
                            <p>
                                C is the correlation normalization constant
                            </p>
                            <p id="sim-norm"></p>
                            <p>
                                The similarity function is known as the <strong>Pearson coefficient</strong>
                            </p>
                        </blockquote>
                        <p>
                            Pearson coefficient gives a value between -1 and 1. It indicates strong positive correlation with +1 and strong negative correlation with -1.
                            Once we have a way to quantify similarity, we can then select the <strong>K</strong> most similar neighbors for a given user.
                            Similarity is serving as a statistical weight, it allows us to compute the <i>collaborative</i> opinions of neighbors
                        </p>
                        <h4>Making rating prediction</h4>
                        <blockquote>
                            <p>
                                The rating prediction for user <strong>u</strong> on movie <strong>i</strong> is given by the following expression:
                            </p>
                            <p id="rating-aggregation"></p>
                            <p>
                                The base line rating is the average movie rating of user <strong>u</strong>. For example, if user <strong>u</strong> has rated 3
                                movies e.g. movie A - 5 stars, ,movie B - 5 stars, and movie C - 2 stars, he has an average rating of 4 stars and that is his baseline.
                            </p>
                            <p id="gamma-factor"></p>
                            <p>
                                Gamma is a normalization constant
                            </p>
                        </blockquote>
                        <p>
                            Given a large data set of user ratings on movies, we can easily compute movie rating predictions for new users that are coming to our system.
                            Once we find highly rated movies, we can push them as product recommendations to users. <strong>However</strong>, kNN suffers from scalability
                            problem. The data set we use contains 260,000 users. For every item we wish to recommend, we need to iterate through 260,000 users to find the k
                            most similar users who also have rated the item. Plus, k-Nearest-Neighbor isn't a real machine learning algorithm. It's time to look at the next
                            algorithm.
                        </p>
                    </section>
                    <section>
                        <h2 class="major">Sparse Matrix SVD</h2>
                        <h4>SVD as in Singular Value Decomposition</h4>
                        <p>
                            Singular value decomposition of a matrix <strong>A</strong> is the factorization of <strong>A</strong> into
                            a product of three matrices A = UDV<sup>T</sup> where the columns of U and V are orthonormal and matrix D is
                            diagonal with positive real numbers. The orthorgonality of the column vectors is a strong property; they form the bases of
                            reconstructing matrix A. However, not all columns contain equal amount of information of the original matrix A. The amount of
                            information each column encodes can be found in the diagonal entries of D matrix. SVD allows us to low rank factorizes
                            a matrix. That means, it allows us to get rid of information of little importance.
                        </p>
                        <h3>Representation</h3>
                        <p>
                            So far what we have gone over is still very vague, let's dive into the movie example.
                        </p>
                        <p>
                            Imagine that we represent movie ratings as a matrix
                        </p>
                        <p id="rating-matrix"></p>
                        <p>
                            The column entries represent user, going from 1 to N and the row entries represent movies
                            going from 1 to m. If this matrix were to be filled completely with rating values, it means that
                            every user must have rated all <strong>m</strong> movies in the database.
                        </p>
                        <p>
                            But of course, that is not the case. In reality, the matrix is a sparse, that is, it's filled
                            with missing rating values.
                        </p>
                        <p id="sparse-matrix"></p>
                        <p>
                            Suppse there is a machine learning algorithm, it is responsible for figuring out
                            what these missing rating values should be. The prediction for the missing values of this matrix is what we use
                            to decide whether a movie is recommendable to user or not.
                        </p>
                        <h4>Prediction for user i on movie j</h4>
                        <p id="single-item-prediction"></p>
                        <h3>
                            Decomposition
                        </h3>
                        <p>
                            Here is how we treat the problem. We imagine that the rating matrix is filled. If we were to perform singular value
                            decomposition on it, we should expect the following:
                        </p>
                        <p id="matrix-decomposition"></p>
                        <p id="dimension"></p>
                        <p><strong>NOTE:</strong> N = p and f = m
                        <p>
                            The left matrix is a N by N real unitary matrix, the middle matrix is a diagonal matrix filled with singular real values,
                            and the right matrix is a m by m real unitary matrix. Each row in the left matrix represents a vector of subjective taste or
                            preference for user <strong>i</strong>. Each column in the right matrix represents a vector of latent feature for movie. A
                            latent feature is like a hidden feature that is not apparent to our common intuition but it does represent correlation in
                            data. Each diagonal value in the middle matrix represents a weight for a particular movie feature and user preference.
                        </p>
                        <p id="linear-combination"></p>
                        <p>
                            Essentially each element of the rating matrix is represented by the linear combination
                            of user preference, movie latent feature, and weight
                        </p>
                    </section>
                    <section>
                        <h2 class="major">Machine Learning</h2>
                        <p>
                            The next step is known as the incremental SVD algorithm developed by Sarwar, Karypis, et al. It was famously used for
                            the Netflix Recommender System competition in 2007. I can't believe it's already been 10 years...
                        </p>

                        <h3>How much error there is</h3>
                        <p id="cost-function"></p>
                        <p>
                            Please note that the f and theta in above expression are vectors. When I multiply theta with f, it means dot product
                            of the two vectors. The cost function captures the error between prediction and actual recorded rating value, plus some
                            regularization factors at the end to prevent overfitting.
                        </p>
                        <h3>Where did Lambda go?</h3>
                        <p>
                            For simplicity of the computation, the lambda is actually absorbed by the preference vector (theta). In standard SVD,
                            these singular values actually represent the statistical weight of the latent factor (preference and feature.) In the incremental
                            SVD algorithm, we don't actually have the information, i.e. the numerical values of these singular values.
                        </p>
                        <p>
                            So we will have to guess...
                        </p>
                        <p>
                            First, try to implement the algorithm with preference/feature vector length = 2, length = 3, length = 5, length = 10, length = 20, preference/feature etc...
                            Then, compare and figure out which yields the best result. As the dimension of the preference/feature vector increases, computation becomes more difficult.
                            I have discovered that result doesn't seem to improve after length = 8, that is keeping only the first 8 singular values.
                        </p>
                        <h3>Optimization Objective</h3>
                        <p>
                            As usual, now we have defined what we are trying to optimize. We want to minimize the prediction error. And to do that,
                            we need to train the function with our <a href="https://grouplens.org/datasets/movielens/"><strong>mega</strong></a> data set.
                            How do we train it? Use the following objective:
                        </p>
                        <p id="objective"></p>
                        <p id="big-theta"></p>
                        <h3>Gradient Descent</h3>
                        <p>
                            The next step is to take partial derivative of the cost function with respect to every entries of every preference vector and feature vector.
                            Then proceed to update each parameter with the following procedure:
                        </p>
                        <p id="dj-df"></p>
                        <p id="dj-dtheta"></p>
                        <p id="prediction"></p>
                        <p>
                            Lorem ipsum dolor sit amet.
                        </p>
                        <h3 class="major">Section 3</h3>
                        <h4>Sub section</h4>
                        <p>
                            Lorem ipsum dolor sit amet.
                        </p>
                    </section>
                </div>
                <!-- Footer -->
                <section id="footer">
                    <div class="inner">
                        <ul class="copyright">
                            <li>&copy; Untitled Inc. All rights reserved.</li><li>Author: <a href="http://github.com/calvinfeng">Calvin Feng</a></li>
                        </ul>
                    </div>
                </section>
            </div>
        </section>
    </div>
    <!-- External library import -->
    <script src="assets/js/lib/skel.min.js"></script>
    <script src="assets/js/lib/jquery.min.js"></script>
    <script src="assets/js/lib/jquery.scrollex.min.js"></script>
    <script src="assets/js/lib/util.js"></script>
    <script src="assets/js/lib/main.js"></script>
    <!-- Custom import -->
    <script src="assets/js/custom/recommender.js"></script>
</body>
</html>
